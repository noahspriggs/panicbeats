Noise Removal
=============

Noise removal is a two-phase effect. In the first phase, the user is asked to select audio they consider noise. That selection is windowed into fixed size chunks, Fourier transforms are calculated, and a noise profile is constructed. The second phase removes noise matching the profile previously selected by the user from a second selected block of audio.

When the users initially selects noise removal they are asked to selected a portion of a track as representative of noise in the signal. This portion of the sound is partitioned into windows, which are then Fourier transformed. The profile is built for each frequency, by choosing the maximum amplitude obtained by that frequency for a fixed number of continuous blocks. This set of maximum amplitudes is stored for use in the second phase.

Once the user has built a noise profile, they must select audio for the noise removal to be applied to. This audio is partitioned into windows of the same size as used when constructing the noise  profile, and Fourier transformed. For each frequency in each window a gain value is determined. The gain value is zero if the amplitude of that frequency is higher than that value in the noise profile, otherwise it is set to a negative value. The gain levels are smoothed for each window, and the gain levels for a given frequency are smoothed bidirectionally across all the windows. The gain is then applied to the complex-valued Fourier transform of the window, and the inverse  Fourier transform applied. However, because the the audio was sliced into windows, the discrete Fourier transform leaves artifacts (called Scalloping Loss) [9]. These are corrected out by applying multiplying each window by a Hann window function. This has the added benefit of concentrating the energy of the signal around the strongest frequency in the audio, assisting in noise removal. The windows are then recombined, overlapping half of the previous window to the next (as the area under the Hann window is 0.5), to produce the final signal.

This approach has a significant weakness: it cannot be done in real-time. The time smoothing function that ensures the amplitude of a frequency does not change too much over time currently uses a lookahead buffer, requiring existing knowledge of the audio yet to be processed. This is easily remedied by using a smoothing function that does not require a lookahead, such as an exponentially weighted moving average.
